---
title: "Academic Publishing: Who is it all for?"
image: /assets/images/2022-10-21/bernd-klutsch-journal-stack-cropped.jpg
---

It's been interesting watching the conversation surrounding
[eLife's](https://elifesciences.org/) change to their publishing model.  Much
of the criticism has been valid and thought provoking, but an awful lot of it
seems to be missing the forest for the trees.

It's clear that many people in academia have little concept of what it's like
to try to access the literature from outside of the institution. Or don't even
seem to realize why anyone outside academia would need to access and understand
the literature. 

The work of academia is not, ultimately, for other academics.  It's for
everyone.  It's about trying to figure out what is and isn't true for the
benefit of all of humanity. 

Academic publishing shouldn't be about just sharing the results of academic
work with other academics, it needs to be about sharing those results with the
rest of the world. 

So when we're assessing changes to academic publishing models, it's important
to assess them through that lense.  What impact does this ultimately have on
the general public's ability to access and understand the work of academia?

![A stack of journals.  Photo by Bernd Klutsch on Unsplash.](/assets/images/2022-10-21/bernd-klutsch-journal-stack-cropped.jpg)

## On the Outside

From outside the institution access to the literature is a mess.

People come into contact with the literature when they have a question they
need an answer to.  A few examples might be the efficacy of a certain health
intervention (or the risks associated with it), the carbon impacts of certain
lifestyle choices, the impacts of a certain local government policy, the safety
of a certain materials, and more.  You might be surprised at the kind of
questions people go searching for answers to every day - from the mundate and
personal, to the profound with societal impacts.

Most people's first stop is Google.  Google doesn't usually turn up the
literature, it turns up secondary sources.  Both those secondary sources often
conflict with each other, and they reference the literature.  And when that
happens, people go down the rabbithole.  What often happens is that the studies
referenced by secondary sources are behind the big journal paywalls.  One study
says "A" another study says "B" and they conflict.

What this person does next differs from person to person, but over a third of
the population has a BA or higher.  This means they have the research skills to
dig deeper, and they often do.  They go looking for more papers on the topic,
trying to figure out whether the answer is "A", "B" or somewhere in between.
What they find are a scattering of open access papers.  Preprints, papers
published in open repos, papers published in open access journals, and more
secondary sources referencing additional papers.

At this point, what they have is partial representation of the literature.  A
home grown literature review that gives them a very incomplete - and therefor
almost certain wrong - picture of what the literature says on a topic.

Science works in the aggregate.  We can only be confident we have the answer to
a question when we've found all the studies published on that question.  Any
individual study can be flawed in a million ways. It's only by zooming out and
looking at the sum total of the research that we can say anything with
confidence.

But for someone outside the institution, with a massive proportion of the
literature sitting behind paywalls, that zoom out is impossible.  This won't
stop people from trying, because people need answers and they will do the best
they can with what they have access to.

So now they have a very small slice of the literature - some of it from
preprints, some open repos, some from peer reviewed studies in journals of a
wide range of reputations (many of questionable repute).  What they don't have
is much from the most reputable journals, because those are behind paywalls.
If they're lucky they'll have found some papers in those journals and will have
been able to read the abstracts.

What they don't know is 



Why does the general public need access to the literature?  Lets take a case
that has become very relavant in the last few years: vaccine hesitancy.

Many people have found themselves in the position of needing to try to help
friends or relatives out of their vaccine hesitancy.  While some amount of
vaccine hesitancy is absolutely driven by various toxic forms of tribalism,
much of it also comes down to people who have lost faith in our regulatory
instutions around health and safety.



## What We Have

In the dominant model, authors submit their work to one or more journals.
Editors send that work out to reviewers, who give feedback which the editor may
use to accept the paper, reject the paper, or request changes.  There's a
feedback loop here, but eventually, the paper is either accepted or rejected.
If it's accepted, it gets published in the journal.  If it's rejected, the
authors can take it to another journal and try to have it published there - at
which point the process repeats.

If the authors want, they can go ahead and submit their papers to a preprint
server to get it out there for feedback while the journal submission process
plays out (or before submitting it to a journal in order to get feedback with
which to polish it).  In some cases authors submit their papers to open
repositories (such as Zenodo) either before or after submission to a journal.

In theory, the peer review process organized by the journals and the
accept/reject decision is the quality control on the academic literature.
Journals have reputations and impact.  Academics seek to publish their papers
in the highest reputation and impact journal they can, and when they fail, they
attempt progressively lower ones until they either get published or give up.

The reputation of the journal is supposed to signal the quality and
trustworthiness of the paper.

## What's it Like on the Outside?

How does this all look from outside the institution?

For starters, the reputation signal is immediately lost. 

Journal's reputations are a social signal.  It's passed from academic to
academic mostly by word of mouth. And if you ask different people about the
reputation of a particular journal, you will get different answers at time.

A social signal like this only exists within the community.  The moment
you step outside of the community, you lose access to the signal.  The average
person has no idea what the reputation of any particular journal is.

Even where they do gain access to the signal for a time, there are around
30,000 academic journals (by most counts), it is impossible to keep track of
which are reputable, which are disreputable, and which are grey.

There have been attempts to quantify that social signal, efforts like
Clarivate's impact factor.  But those efforts are mostly not legible to the lay
public.  Ask the average person what impact factor is, and they won't have a
clue.

And that even assumes someone looking in from the outside even finds the
journal.  Most of the most reputable journals are subscription based, meaning
they charge anywhere from $30 to $50 per paper. 


